From aa4e0ca0ef94ab5afb53a75995901455190131dc Mon Sep 17 00:00:00 2001
From: revsic <revsic99@gmail.com>
Date: Thu, 3 Sep 2020 01:03:03 +0900
Subject: [PATCH] generate: Fix indent and load_state_dict

---
 generate.py | 24 ++++++++++++------------
 1 file changed, 12 insertions(+), 12 deletions(-)

diff --git a/generate.py b/generate.py
index 4255c8c..ab4eab4 100644
--- a/generate.py
+++ b/generate.py
@@ -9,17 +9,17 @@ def generate(args, g_ema, device, mean_latent):
     with torch.no_grad():
         g_ema.eval()
         for i in tqdm(range(args.pics)):
-           sample_z = torch.randn(args.sample, args.latent, device=device)
-
-           sample, _ = g_ema([sample_z], truncation=args.truncation, truncation_latent=mean_latent)
-           
-           utils.save_image(
-            sample,
-            f'sample/{str(i).zfill(6)}.png',
-            nrow=1,
-            normalize=True,
-            range=(-1, 1),
-        )
+            sample_z = torch.randn(args.sample, args.latent, device=device)
+
+            sample, _ = g_ema([sample_z], truncation=args.truncation, truncation_latent=mean_latent)
+
+            utils.save_image(
+                sample,
+                f'sample/{str(i).zfill(6)}.png',
+                nrow=1,
+                normalize=True,
+                range=(-1, 1),
+            )
 
 if __name__ == '__main__':
     device = 'cuda'
@@ -44,7 +44,7 @@ if __name__ == '__main__':
     ).to(device)
     checkpoint = torch.load(args.ckpt)
 
-    g_ema.load_state_dict(checkpoint['g_ema'])
+    g_ema.load_state_dict(checkpoint['g_ema'], strict=False)
 
     if args.truncation < 1:
         with torch.no_grad():
-- 
2.21.0.windows.1

